{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4198e5ab",
   "metadata": {},
   "source": [
    "# **Subset CONUS and do a ParFlow Spinup**\n",
    "### This notebook has two principal sections: \n",
    "1. Subset all static inputs from a CONUS run stored in Hydrodata \n",
    "2. Load and alter a reference run to spin-up your subset ParFlow domain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f0f4110",
   "metadata": {},
   "source": [
    "### Import the required libraries for step one (subsetting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c960423",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from parflow import Run\n",
    "from parflow.tools.fs import mkdir\n",
    "from parflow.tools.settings import set_working_directory\n",
    "from subsettools.subsettools import *\n",
    "from subsettools.datasets import get_ref_yaml_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd0f9348",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 1. Define variables to access datasets to subset in Hydrodata and define write paths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed93b3b2",
   "metadata": {},
   "source": [
    "#### We will be testing with the Upper Verde watershed for this example\n",
    "- HUC: 15060202\n",
    "- Size: 6496 km^2 (ni = 112, nj = 90)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "808c9620",
   "metadata": {},
   "source": [
    "#### Set your variables to specify which static and climate forcing data you would like to subset in Hydrodata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dfbdea78",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "runname = \"spinup_test\"\n",
    "\n",
    "# provide a way to create a subset from the conus domain (huc, lat/lon bbox currently supported)\n",
    "huc_list = [\"15060202\"]\n",
    "\n",
    "# provide information about the datasets you want to access for run inputs using the data catalog\n",
    "start = \"2005-10-01\"\n",
    "wy = 2006\n",
    "grid = \"conus1\"\n",
    "run_ds = \"conus1_baseline_mod\"\n",
    "var_ds = \"conus1_domain\"\n",
    "P = 1\n",
    "Q = 1\n",
    "\n",
    "# Set the directory paths where you want to write your subset files\n",
    "home = os.path.expanduser(\"~\")\n",
    "base_dir = os.path.join(home, \"subsettools_tutorial\")\n",
    "input_dir = os.path.join(base_dir, \"inputs\", f\"{runname}_{grid}_{wy}WY_spinup\")\n",
    "output_dir = os.path.join(base_dir, \"outputs\")\n",
    "static_write_dir = os.path.join(input_dir, \"static\")\n",
    "mkdir(static_write_dir)\n",
    "pf_out_dir = os.path.join(output_dir, f\"{runname}_{grid}_{wy}WY_spinup\")\n",
    "mkdir(pf_out_dir)\n",
    "\n",
    "# set PARFLOW_DIR path to the preferred version of ParFlow\n",
    "os.environ[\"PARFLOW_DIR\"] = \"/home/SHARED/software/parflow/3.10.0\"\n",
    "\n",
    "# reference_run = get_ref_yaml_path(grid)\n",
    "reference_run = get_ref_yaml_path(grid, \"spinup\", \"solid\")\n",
    "target_runscript = os.path.join(pf_out_dir, runname + \".yaml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa7ab970",
   "metadata": {},
   "source": [
    "### 2. Get the desired ParFlow x/y bbox from user provided geospatial information "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d50bbca",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ij_bounds returns [imin, jmin, imax, jmax]\n",
      "bounding box: [375, 239, 487, 329]\n",
      "nj: 90\n",
      "ni: 112\n"
     ]
    }
   ],
   "source": [
    "ij_bounds = huc_to_ij(huc_list=huc_list, grid=grid)\n",
    "print(\"ij_bounds returns [imin, jmin, imax, jmax]\")\n",
    "print(f\"bounding box: {ij_bounds}\")\n",
    "\n",
    "nj = ij_bounds[3] - ij_bounds[1]\n",
    "ni = ij_bounds[2] - ij_bounds[0]\n",
    "print(f\"nj: {nj}\")\n",
    "print(f\"ni: {ni}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0362322",
   "metadata": {},
   "source": [
    "### 3. Make the mask and solid file\n",
    "You only do this if you provided a huc or a shapefile where we can extract a mask from the conus tif. Otherwise, the reference run is rewritten to provide a box domain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c3aec38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grid is conus1\n",
      "Wrote mask.pfb\n",
      "Wrote solidfile.pfsol and mask_vtk.vtk with total z of 500 meters\n"
     ]
    }
   ],
   "source": [
    "create_mask_solid(huc_list=huc_list, grid=grid, write_dir=static_write_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1567e0ff",
   "metadata": {},
   "source": [
    "### 4. Subset the static ParFlow inputs\n",
    "Two options to subset static inputs. \n",
    "1. subset_static(): This function when provided with a variable dataset hosted on hydrodata will subset all static inputs required to do a baseline run from the default argument var_list without the user specify specific files. Pressure is the steady state pressure. If a user would like the override this, they may pass in their own value for var_list and their specifed variables in the target dataset will be subset. \n",
    "\n",
    "3. subset_press_init(): This function will write the subset pressure of the last hour in the last day before your start date. If no such pressure file exists in the hydrodata run dataset specifed, no file will be written. The function assumes UTC of zero as the default, but allows the user to override. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec16ed87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote slope_x.pfb in specified directory.\n",
      "Wrote slope_y.pfb in specified directory.\n",
      "Wrote pf_indicator.pfb in specified directory.\n",
      "mannings not found in dataset conus1_domain\n",
      "depth_to_bedrock not found in dataset conus1_domain\n",
      "Wrote pme.pfb in specified directory.\n",
      "Wrote ss_pressure_head.pfb in specified directory.\n"
     ]
    }
   ],
   "source": [
    "subset_static(ij_bounds, dataset=var_ds, write_dir=static_write_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "33d3e618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote conus1_baseline_mod_2005.09.30:23.00.00_UTC0_press.pfb in specified directory.\n"
     ]
    }
   ],
   "source": [
    "press_init_filename = subset_press_init(\n",
    "    ij_bounds, dataset=run_ds, date=start, write_dir=static_write_dir, time_zone=\"UTC\"\n",
    ")\n",
    "# subset_press_init(ij_bounds, dataset = run_ds, date = start, write_dir = static_write_dir, time_zone = 'America/New_York')\n",
    "# subset_press_init(ij_bounds, dataset = run_ds, date = start, write_dir = static_write_dir, time_zone = 'US/Central')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b69c80",
   "metadata": {},
   "source": [
    "### 8. Set up a baseline run from a reference yaml\n",
    "This function will return the correct template yaml file to do your run based on the grid, if you're doing spin-up and if you're using a solid file with the necessary keys changed to run your subset with selected climate forcing at baseline for one year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ea1f0e8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New runname: spinup_test provided, a new yaml file will be created\n",
      "No forcing directory provided, run.Solver.CLM.MetFilePath key not set\n",
      "ComputationalGrid.NY set to 90 and NX to 112\n",
      "GeomInput.domaininput.InputType detected as SolidFile, no additional keys to change for subset\n",
      "Updated runscript written to /home/ga6/subsettools_tutorial/outputs/spinup_test_conus1_2006WY_spinup\n"
     ]
    }
   ],
   "source": [
    "target_runscript = edit_runscript_for_subset(\n",
    "    ij_bounds, runscript_path=reference_run, write_dir=pf_out_dir, runname=runname\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f742051",
   "metadata": {},
   "source": [
    "### 9. Copy over your static files to your run directory\n",
    "As a seperate function as you may only need to do this once, or you may want to copy subset static files to different run directories "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "71ae6dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_static_files(read_dir=static_write_dir, write_dir=pf_out_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c1fe950",
   "metadata": {},
   "source": [
    "### 10. Change the file names in your runscript if desired\n",
    "If you have changed the name of a static input file either from those used in the reference yamls provided on X GitHub repo, or have changed the name of an individual file for an ensemble or other experiment, you can change it with this function by providing the target runscript (yaml or pfidb) and the new file name(s) as an arguments. Only those arguments with a specified file name will be updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e0288e27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial pressure filename changed to conus1_baseline_mod_2005.09.30:23.00.00_UTC0_press.pfb\n",
      "Updated runscript written to /home/ga6/subsettools_tutorial/outputs/spinup_test_conus1_2006WY_spinup\n"
     ]
    }
   ],
   "source": [
    "target_runscript = change_filename_values(\n",
    "    runscript_path=target_runscript,\n",
    "    write_dir=pf_out_dir,\n",
    "    init_press=press_init_filename,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b14cf608",
   "metadata": {},
   "source": [
    "### 11. Change processor topolgoy if desired and then distribute your inputs and forcings to match the new topology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "24c155b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no forcing dir provided, only distributing static inputs\n",
      "Distributed mask.pfb with NZ 1\n",
      "Distributed slope_x.pfb with NZ 1\n",
      "Distributed slope_y.pfb with NZ 1\n",
      "Distributed pf_indicator.pfb with NZ 5\n",
      "Distributed pme.pfb with NZ 5\n",
      "Distributed ss_pressure_head.pfb with NZ 5\n",
      "Distributed conus1_baseline_mod_2005.09.30:23.00.00_UTC0_press.pfb with NZ 5\n"
     ]
    }
   ],
   "source": [
    "dist_run(\n",
    "    P=P,\n",
    "    Q=Q,\n",
    "    runscript_path=target_runscript,\n",
    "    write_dir=pf_out_dir,\n",
    "    dist_clim_forcing=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb7c01e",
   "metadata": {},
   "source": [
    "### 12. Do a baseline run.\n",
    "Load in the yaml run file you've created which is in the same folder as your static forcings and points to your desired Climate forcings. This assumes you do not want to make any changes from the parent model you used (Ex. conus1 baseline) and will run your subset at baseline conditions. Outputs should be almost identical to the parent model at your subset location for the same time period if you make no additional changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "abbc70fa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded run with runname: spinup_test\n",
      "\n",
      "# ==============================================================================\n",
      "# ParFlow directory\n",
      "#  - /home/SHARED/software/parflow/3.10.0\n",
      "# ParFlow version\n",
      "#  - 3.10.0\n",
      "# Working directory\n",
      "#  - /home/ga6/subsettools_tutorial/outputs/spinup_test_conus1_2006WY_spinup\n",
      "# ParFlow database\n",
      "#  - spinup_test.pfidb\n",
      "# ==============================================================================\n",
      "\n",
      "\n",
      "# ==============================================================================\n",
      "# ParFlow ran successfully ðŸ’¦ ðŸ’¦ ðŸ’¦ \n",
      "# ==============================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "set_working_directory(pf_out_dir)\n",
    "\n",
    "# load the specified run script\n",
    "run = Run.from_definition(target_runscript)\n",
    "print(f\"Loaded run with runname: {run.get_name()}\")\n",
    "\n",
    "# The following line shows timing info that is likely important for interacting with your spin-up run\n",
    "\n",
    "# run.TimingInfo.BaseUnit = 1.0\n",
    "# run.TimingInfo.StartCount = 0\n",
    "# run.TimingInfo.StartTime = 0\n",
    "# normally set to something like 1000000.0 but shorter for demo purposes\n",
    "run.TimingInfo.StopTime = 48.0\n",
    "run.TimingInfo.DumpInterval = 24.0\n",
    "\n",
    "# run.TimeStep.Type = 'Growth'\n",
    "# run.TimeStep.InitialStep = .01\n",
    "# run.TimeStep.GrowthFactor = 1.1\n",
    "# run.TimeStep.MaxStep = 250.0\n",
    "# run.TimeStep.MinStep = 0.0001\n",
    "\n",
    "run.run(working_directory=pf_out_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe23a9ae",
   "metadata": {},
   "source": [
    "### 13. Restart a parflow run\n",
    "If you need to restart a run to complete a spinup, transient run, etc then you can run the following to make the necessary updates to your runscript and then overwrite it in place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7209d80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# restart_run(target_runscript)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
