{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d50e013",
   "metadata": {},
   "source": [
    "# **Subset CONUS and run ParFlow-CLM**\n",
    "\n",
    "To launch this notebook interactively in a Jupyter notebook-like browser interface, please click the \"Launch Binder\" button below. Note that Binder may take several minutes to launch.\n",
    "\n",
    "[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/hydroframe/subsettools/HEAD?labpath=docs%2Fexample_notebooks%2Fconus2_subsetting_transient.ipynb)\n",
    "\n",
    "This notebook walks through an example of subsetting a HUC8 from the CONUS2 domain. This example will subset everything needed to do a transient run with ParFlow-CLM. \n",
    "This is includes all hydrogeologic datasets as well as climate forcing data from CW3E. All of the data is written to a folder for the specified days to run. This example uses the template runscript conus2_pfclm_transient_solid.yaml and edits it to correspond with the domain subset. It also sets-up and performs the designed simulation. The result will be model output pressure and saturation pfbs according to the days specified.\n",
    "\n",
    "### This notebook has two principal sections: \n",
    "1. Subset all static inputs and climate forcings from a CONUS run stored in Hydrodata \n",
    "2. Load and alter a reference run to set up and perform your ParFlow-CLM subset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "134427aa",
   "metadata": {},
   "source": [
    "### Import the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84c7594b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from parflow import Run\n",
    "from parflow.tools.io import read_pfb, read_clm\n",
    "from parflow.tools.fs import mkdir\n",
    "from parflow.tools.settings import set_working_directory\n",
    "import subsettools as st\n",
    "import hf_hydrodata as hf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93b0c616-c6c3-4b0e-ab55-b8caff0594cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You need to register on https://hydrogen.princeton.edu/pin before you can use the hydrodata utilities\n",
    "hf.register_api_pin(\"your_email\", \"your_pin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec636a8a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 1. Define variables to access datasets in Hydrodata to subset and define write paths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb358b8",
   "metadata": {},
   "source": [
    "#### We will be testing with the Middle James-Buffalo watershed in Virginia for this example\n",
    "\n",
    "REMEMBER: CONUS 1 and 2 have different domains, a HUC that will run in CONUS2 may not be in the CONUS1 domain\n",
    "\n",
    "- HUC ID: 02080203\n",
    "- Size: 5240 km^2 (ni = 91, nj = 89)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "897c0d79",
   "metadata": {},
   "source": [
    "#### Set your variables to specify which static and climate forcing data you would like to subset in Hydrodata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2fb131aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "runname = \"conus2_mjb\"\n",
    "\n",
    "# provide a way to create a subset from the conus domain (huc, lat/lon bbox currently supported)\n",
    "huc_list = [\"02080203\"]\n",
    "# provide information about the datasets you want to access for run inputs using the data catalog\n",
    "start = \"2005-10-01\"\n",
    "end = \"2005-10-03\"\n",
    "grid = \"conus2\"\n",
    "var_ds = \"conus2_domain\"\n",
    "forcing_ds = \"CW3E\"\n",
    "# cluster topology\n",
    "P = 1\n",
    "Q = 1\n",
    "\n",
    "# set the directory paths where you want to write your subset files\n",
    "home = os.path.expanduser(\"~\")\n",
    "base_dir = os.path.join(home, \"subsettools_tutorial\")\n",
    "input_dir = os.path.join(base_dir, \"inputs\", f\"{runname}_{grid}_{end[:4]}WY\")\n",
    "output_dir = os.path.join(base_dir, \"outputs\")\n",
    "static_write_dir = os.path.join(input_dir, \"static\")\n",
    "mkdir(static_write_dir)\n",
    "forcing_dir = os.path.join(input_dir, \"forcing\")\n",
    "mkdir(forcing_dir)\n",
    "pf_out_dir = os.path.join(output_dir, f\"{runname}_{grid}_{end[:4]}WY\")\n",
    "mkdir(pf_out_dir)\n",
    "\n",
    "# Set the PARFLOW_DIR path to your local installation of ParFlow.\n",
    "# This is only necessary if this environment variable is not already set.\n",
    "# os.environ[\"PARFLOW_DIR\"] = \"/path/to/your/parflow/installation\"\n",
    "\n",
    "# load your preferred template runscript\n",
    "reference_run = st.get_template_runscript(grid, \"transient\", \"solid\", pf_out_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "672812cb",
   "metadata": {},
   "source": [
    "### 2. Get the desired ParFlow i/j bbox from user provided geospatial information "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d50bbca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ij_bounds = st.huc_to_ij(huc_list=huc_list, grid=grid)\n",
    "print(\"ij_bound returns [imin, jmin, imax, jmax]\")\n",
    "print(f\"bounding box: {ij_bounds}\")\n",
    "\n",
    "nj = ij_bounds[3] - ij_bounds[1]\n",
    "ni = ij_bounds[2] - ij_bounds[0]\n",
    "print(f\"nj: {nj}\")\n",
    "print(f\"ni: {ni}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83807022",
   "metadata": {},
   "source": [
    "### 3. Make the mask and solid file\n",
    "You only do this if you providin a huc or list of hucs. Otherwise, the reference run provided is for a box domain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3aec38",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_solid_paths = st.create_mask_solid(huc_list=huc_list, grid=grid, write_dir=static_write_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da721b9",
   "metadata": {},
   "source": [
    "### 4. Subset the static ParFlow inputs\n",
    "Two options to subset static inputs. \n",
    "1. subset_static(): This function when provided with a variable dataset hosted on Hydrodata will subset all static inputs required to do a baseline run from the default argument var_list without the user specifying specific files. Pressure is the steady state pressure. If a user would like the override this, they may pass in their own value for var_list and their specifed variables in the target dataset will be subset. \n",
    "\n",
    "2. subset_press_init(): This function will write the subset pressure of the last hour in the last day before your start date in the given time zone. If no such pressure file exists in the hydrodata run dataset specifed, no file will be written. The function assumes UTC0 as the default and will return 11PM UTC0. You can override this by providing a timezone. \n",
    "\n",
    "**Note: In when working with the CONUS2 domain, there are no currently no available transient runs, so we will start runs from the steady state pressure file returned by subset_static().** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec16ed87",
   "metadata": {},
   "outputs": [],
   "source": [
    "static_paths = st.subset_static(ij_bounds, dataset=var_ds, write_dir=static_write_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afefaac7",
   "metadata": {},
   "source": [
    "### 5. Configure CLM drivers\n",
    "This function will get the clm drivers that are associated with your run dataset (same dataset as where you got your initial pressure file). Vegm, vegp and drv_clmin will be written into your specified static input directory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6f4133f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing vegp\n",
      "copied vegp\n",
      "processing vegm\n",
      "subset vegm\n",
      "processing drv_clm\n",
      "copied drv_clmin\n",
      "edited drv_clmin\n"
     ]
    }
   ],
   "source": [
    "clm_paths = st.config_clm(ij_bounds, start=start, end=end, dataset=var_ds, write_dir=static_write_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "002c117a",
   "metadata": {},
   "source": [
    "### 6. Subset the climate forcing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f9e57c",
   "metadata": {},
   "source": [
    "This function will write all variables needed to run CLM for your specified forcing dataset, on your specified grid, subset to the i/j boundary that was returned previously within the specified start and end date. This function assumes UTC0 by default, but you can override it by providing a timezone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f34c4be7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading precipitation pfb sequence\n",
      "Reading downward_shortwave pfb sequence\n",
      "Reading downward_longwave pfb sequence\n",
      "Reading specific_humidity pfb sequence\n",
      "Reading air_temp pfb sequence\n",
      "Reading atmospheric_pressure pfb sequence\n",
      "Reading east_windspeed pfb sequence\n",
      "Reading north_windspeed pfb sequence\n",
      "Finished writing downward_longwave to folder\n",
      "Finished writing air_temp to folder\n",
      "Finished writing specific_humidity to folder\n",
      "Finished writing east_windspeed to folder\n",
      "Finished writing north_windspeed to folder\n",
      "Finished writing atmospheric_pressure to folder\n",
      "Finished writing downward_shortwave to folder\n",
      "Finished writing precipitation to folder\n"
     ]
    }
   ],
   "source": [
    "forcing_paths = st.subset_forcing(\n",
    "    ij_bounds,\n",
    "    grid=grid,\n",
    "    start=start,\n",
    "    end=end,\n",
    "    dataset=forcing_ds,\n",
    "    write_dir=forcing_dir,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c65a6b",
   "metadata": {},
   "source": [
    "### 7. Spot check subset static and climate forcing with plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c235d3",
   "metadata": {},
   "source": [
    "#### Check a static input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ce138b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.chdir(static_write_dir)\n",
    "file_name = \"pf_indicator.pfb\"\n",
    "data = read_pfb(file_name)[7] \n",
    "print(data.shape)\n",
    "\n",
    "plt.imshow(data, cmap=\"Reds\", origin=\"lower\")\n",
    "plt.colorbar()\n",
    "plt.title(file_name, fontsize = 14)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b69c80",
   "metadata": {},
   "source": [
    "### 8. Set up a baseline run from a reference yaml\n",
    "This function will return the correct template yaml file to do your run based on the grid, if you're doing spin-up and if you're using a solid file with the necessary keys changed to run your subset with selected climate forcing at baseline for your specified start and end dates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea1f0e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "runscript_path = st.edit_runscript_for_subset(\n",
    "    ij_bounds,\n",
    "    runscript_path=reference_run,\n",
    "    runname=runname,\n",
    "    forcing_dir=forcing_dir,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42573426",
   "metadata": {},
   "source": [
    "### 9. Copy over your static files to your run directory\n",
    "You may only need to do this once, or you may want to copy subset static files to different run directories for different runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "71ae6dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "st.copy_files(read_dir=static_write_dir, write_dir=pf_out_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57ca532c",
   "metadata": {},
   "source": [
    "### 10. Change the file names in your runscript if desired\n",
    "If you have changed the name of a static input file either from those used in the reference yamls provided, or have changed the name of an individual file for an ensemble or other experiment, you can change it with this function by providing the target runscript (yaml or pfidb) and the new file name(s) as an arguments. Only those arguments with a specified file name will be updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0288e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "init_press_path = os.path.basename(static_paths[\"ss_pressure_head\"])\n",
    "depth_to_bedrock_path = os.path.basename(static_paths[\"pf_flowbarrier\"])\n",
    "\n",
    "runscript_path = st.change_filename_values(\n",
    "    runscript_path=runscript_path,\n",
    "    init_press=init_press_path,\n",
    "    depth_to_bedrock = depth_to_bedrock_path\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab74c48",
   "metadata": {},
   "source": [
    "### 11. Change processor topology if desired and then distribute your inputs and forcings to match the new topology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c155b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "runscript_path = st.dist_run(\n",
    "    P=P,\n",
    "    Q=Q,\n",
    "    runscript_path=runscript_path,\n",
    "    dist_clim_forcing=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6081f81",
   "metadata": {},
   "source": [
    "### 12. Do a baseline run.\n",
    "Load in the yaml run file you've created which is in the same folder as your static forcings and points to your climate forcing data. This assumes you do not want to make any changes from the parent model you used (Ex. conus1 baseline) and will run your subset at baseline conditions. Outputs should be almost identical to the parent model at your subset location for the same time period if you make no additional changes.\n",
    "\n",
    "**Notes about run speed**\n",
    "\n",
    "There are several things that may cause your run to take longer than expect. First, look at the file ending with your_runname.out.kinsol.log. If it is updating, it means your system is trying to solve. \n",
    "\n",
    "1. You may be trying to run too large a domain for the number of cores \n",
    "2. There is heavy rain on the day or days you selected, making the system harder to solve\n",
    "3. The initial (time 0) step can often take longer to run\n",
    "4. You have made a large change to one of your inputs. The change you made may mean the initial pressure file doesn't \"match up\" with your input. Try to run your subset model in spinup mode first, and then return to transient mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abbc70fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "set_working_directory(f\"{pf_out_dir}\")\n",
    "print(pf_out_dir)\n",
    "\n",
    "# load the specified run script\n",
    "run = Run.from_definition(runscript_path)\n",
    "print(f\"Loaded run with runname: {run.get_name()}\")\n",
    "\n",
    "# The following line is setting the run just for 10 hours for testing purposes\n",
    "run.TimingInfo.StopTime = 10\n",
    "\n",
    "# The following line updates the root name of your climate forcing. You can comment it out if using NLDAS datasets. \n",
    "run.Solver.CLM.MetFileName = 'CW3E'\n",
    "\n",
    "run.run(working_directory=pf_out_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
