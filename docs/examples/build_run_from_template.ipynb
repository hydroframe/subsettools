{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4768bbb9-77eb-4e56-83c9-0dbcbd35ff39",
   "metadata": {},
   "source": [
    "# Build a ParFlow run from a template"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83fb9a68-dca3-4193-9885-40f07596f6ba",
   "metadata": {},
   "source": [
    "The subsettools package comes with a collection of template ParFlow runscripts which you can use as a starting point in constructing a ParFlow model. \n",
    "\n",
    "For a complete workflow subsetting and running ParFlow simulations refer to the [example_notebooks](https://hydroframesubsettools.readthedocs.io/en/api-fix/example_notebooks/example_notebooks.html) section.  Here we walk through more details on how to customize a run for your needs. Also note that if none of the template run scripts suite your needs there is a wide variety of test scripts and examples available through the ParFlow Repo and ParFlow short courses for a complete list of ParFlow Resources checkout the [HydroFrame website](https://hydroframe.org/parflow).\n",
    "\n",
    "You will have the following choices in selecting a template run script: \n",
    "1. **Select the ParFlow configuration you would like to start from**: We have templates for the ParFlow [CONUS1](https://hydroframe.org/pfconus1) and [CONUS2](https://hydroframe.org/pfconus2) domains. There are many differences between these domains which you can read about through the previous links. Generally speaking though the `CONUS2` model is the most up to date domain and is an advancement from the `CONUS1` domain. The `CONUS2` model has a deeper vertical extent, more vertical layers, updated topographic processing and updated subsurface geology from the `CONUS1` model\n",
    "2. **Determine whether you will run a box or solid file domain**: A solid file can be used to define an irregular domain boundary (e.g. a watershed boundary). If you run with a solid file only the cells within the solid file will be designated as active. Alternatively you can create a box domain that encompasses your desired watershed boundary. There is no inherently better choice between these two. Solid file domains allow you to impose irregular boundaries and limit the active computational domain but box domains can be simpler to work with. \n",
    "3. **Determine what type of simulation you would like to do**: There are two choices: \n",
    "    - **Spinup**: This template will run ParFlow with a constant recharge forcing at the upper boundary. This approach is used to initialize the groundwater configuration in a process called spinup (refer to the [spinup workflow notebook](https://hydroframesubsettools.readthedocs.io/en/edit-docs/example_notebooks/conus1_subsetting_spinup.html)for a full example of this).  \n",
    "    - **Transient**: This template if for a transient ParFlow-CLM run. If you choose this option you will need to subset forcing files for your simulation (i.e. Precipitation, temperature, etc.) and you will also need a clm driver file (refer to the [transient workflow notebook](https://hydroframesubsettools.readthedocs.io/en/edit-docs/example_notebooks/conus1_subsetting_transient.html)for a full example of this)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca2c2037",
   "metadata": {},
   "source": [
    "## Edits -- DELETE LATER\n",
    "- @Reed for #2 on the list above what is the best reference to point them to for the difference between a box and solid file domain. One of the short courses? \n",
    "- @Reed -- probably for later but we should add a single column run script template to this list.\n",
    "- @George and @Reed I took the ij bounds stuff out of here and made a separate tutorial for it so we don't have to include that in all of these. If you like that approach we need to modify the intro to the 'definte_subset.ipynb' that I created and then we can take it out of the other tutorials too. *George:* I like that approach, I added package imports to make this notebook runable too."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a421017a",
   "metadata": {},
   "source": [
    "### 1.  Setup \n",
    "\n",
    "In all examples you will need to import the following packages and register your pin in order to have access to the HydroData datasets.\n",
    "\n",
    "Refer to the [getting started](https://hydroframesubsettools.readthedocs.io/en/latest/getting_started.html) instructions for creating your pin if you have not done this already."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61d84526-545e-41c4-a7c2-c2c4aee3f878",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subsettools as st\n",
    "import hf_hydrodata as hf\n",
    "from parflow import Run\n",
    "\n",
    "hf.register_api_pin(\"your_email\", \"your_pin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f5f9e0-4541-47d1-ba06-d73e0a9c3f98",
   "metadata": {},
   "source": [
    "### 2. Get a template runscript\n",
    "\n",
    "There are multiple ways to run ParFlow models you can learn more about these approaches at (https://hydroframe.org/parflow). Here will will be using a workflow based on .yaml files and python tools. You can read more about pftools and python functions for manipulating runscripts [here](https://parflow.readthedocs.io/en/latest/python/run_script.html).\n",
    "\n",
    "As noted above we have provided template run scripts for the CONUS1 and CONUS2 model domains that you can use to start your simulation.  \n",
    "\n",
    "To get a template runscript provided with the package, you should use the `get_template_runscript` function (API reference [here](https://hydroframesubsettools.readthedocs.io/en/edit-docs/autoapi/subsettools/datasets/index.html#subsettools.datasets.get_template_runscript)). The function will get the correct template runscript based on your choices, write it to your chosen directory, and return the path to the file written.\n",
    "\n",
    "For example, to get the template for a coupled ParFlow-CLM run on the CONUS1 grid with a solid input file, you can do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0331f10f-633d-4ece-9474-36c4641525c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "template_run = st.get_template_runscript(\n",
    "    grid=\"conus1\", \n",
    "    mode=\"transient\", \n",
    "    input_file_type=\"solid\",\n",
    "    write_dir=\"/path/to/your/write/directory\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c5498c-2295-4541-9a43-750de0fc365f",
   "metadata": {},
   "source": [
    "**NOTE:** At this point we have retrieved exactly the run script for the national simulations. We have not made any customizations to it and you would not expect it to run. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad6fc9a",
   "metadata": {},
   "source": [
    "### 3. Explore the keys of the run script you obtained\n",
    "You can inspect the yaml file that was returned to you manually the same way you would look at any other yaml file.  The ParFlow manual provides a complete reference for all model keys [here](https://parflow.readthedocs.io/en/latest/keys.html)\n",
    "\n",
    "In addition you create a ParFlow run object from a runscript file with the `from_definition` method of the ParFlow `Run` class and then explore any keys directly from this. \n",
    "\n",
    "Here are a few examples (refer to the python [run script documentation](https://parflow.readthedocs.io/en/latest/python/run_script.html) for more information):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53100619-3728-428d-bc03-444c13c08ad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processor Topology: 4 4 1\n",
      "Dimensions nx, ny, nz: 3342 1888 5\n",
      "Number of dz scallers: 5\n",
      "dz scallers: 1.0 0.01 0.006 0.003 0.001\n",
      "Indicator group names: ['s1', 's2', 's3', 's4', 's5', 's6', 's7', 's8', 's9', 's10', 's11', 's12', 's13', 'g1', 'g2', 'g3', 'g4', 'g5', 'g6', 'g7', 'g8', 'b1', 'b2']\n",
      "Hydraulic conductivity for the indicator group 's1': 0.269022595 m/hour\n",
      "Hydraulic conductivity for the indicator group 'b1': 0.005 m/hour\n"
     ]
    }
   ],
   "source": [
    "run = Run.from_definition(template_run)\n",
    "\n",
    "# For example we can look at the processor topology like this: \n",
    "print(\"Processor Topology:\", run.Process.Topology.P, run.Process.Topology.Q, run.Process.Topology.R )\n",
    "\n",
    "# and the domain configuraton like this\n",
    "print(\"Dimensions nx, ny, nz:\", run.ComputationalGrid.NX, run.ComputationalGrid.NY, run.ComputationalGrid.NZ)\n",
    "print(\"Number of dz scallers:\", run.dzScale.nzListNumber)\n",
    "print(\n",
    "    \"dz scallers:\",\n",
    "    run.Cell._0.dzScale.Value,\n",
    "    run.Cell._1.dzScale.Value,\n",
    "    run.Cell._2.dzScale.Value,\n",
    "    run.Cell._3.dzScale.Value,\n",
    "    run.Cell._4.dzScale.Value,\n",
    ")\n",
    "\n",
    "# We can also print subsurface properties, like the hydraulic conductivity values: \n",
    "print(\"Indicator group names:\", run.Geom.Perm.Names[1:])\n",
    "# print the values for some of the indicator groups:\n",
    "print(\"Hydraulic conductivity for the indicator group \\'s1\\':\", run.Geom.s1.Perm.Value, \"m/hour\")\n",
    "print(\"Hydraulic conductivity for the indicator group \\'b1\\':\", run.Geom.b1.Perm.Value, \"m/hour\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a09dfacf-f441-4003-a24f-85781a161021",
   "metadata": {},
   "source": [
    "### 4. Modify a template runscript for a subset domain \n",
    "The runscript template is configured for a national simulation To run on a smaller domain you need to: \n",
    "1. Adjust the size of the model to match your subset domain\n",
    "2. Update the path to the model input files to match the clipped inputs for your subset domain (refer to the subset tutorials or sample workflow for examples of subsetting input files)\n",
    "\n",
    "You can make any of these changes yourself manually by modifying the yaml file directly or following the example shown in `Section 7 ` to modify the run object. Here we demonstrate two wrapper functions that will set multiple keys at once to help with this task. \n",
    "\n",
    "#### 4.1 Modify the size of the model domain to math your subset\n",
    "First we adjust the size of the model run (nx, ny) to match the dimensions of our subset area which we obtain using the i,j bounds function and provide the path to the subset forcing files. \n",
    "\n",
    "The `edit_runscript_for_subset` function (API reference [here](https://hydroframesubsettools.readthedocs.io/en/edit-docs/autoapi/subsettools/subsettools/index.html#subsettools.subsettools.edit_runscript_for_subset)) will accomplish these two jobs. \n",
    "\n",
    "**NOTE:** *If you don't provide a write_dir argument, the new runscript is going to be written in the directory or the original runscript. The filename depends on the runname, so if you also don't change the runname the original runscript file will be overwritten.*\n",
    "\n",
    "@George its confusing to me why the path to the forcing files is updated in this function but all the other paths are in the next function. \n",
    ">>> The forcing directory won't change any filenames, but it tells the script where to find the forcing files. Conceptually, maybe it does not fit very well in the change_filename_values function. This was the way these two functions were designed even before I started working on this, and I kept the original design. But we could always add an additional argument to change_filename_values if you feel it would work better there. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97d055f7-5a38-4f5b-8332-bbf6dd84b1d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bounding box: (2285, 436, 2358, 495)\n",
      "New runname: my_new_conus1_run provided, a new yaml file will be created\n",
      "Climate forcing directory has been changed to /home/ga6/subsettools_example in runscript.\n",
      "ComputationalGrid.NY set to 59 and NX to 73\n",
      "GeomInput.domaininput.InputType detected as SolidFile, no additional keys to change for subset\n",
      "Updated runscript written to /home/ga6/subsettools_example\n",
      "----------------------------------------------------------------------------------------------------\n",
      "New runname: my_new_conus1_run\n",
      "New grid nx, ny: 73 59\n",
      "Forcing directory: /home/ga6/subsettools_example\n"
     ]
    }
   ],
   "source": [
    "#Set the ij bounds for the new model\n",
    "ij_box_bounds = st.latlon_to_ij(latlon_bounds=[[37.91, -91.43], [37.34, -90.63]], grid=\"conus1\")\n",
    "print(f\"bounding box: {ij_box_bounds}\") \n",
    "\n",
    "#Edit the runscript to match this subset\n",
    "runscript_path = st.edit_runscript_for_subset(\n",
    "    ij_bounds=ij_box_bounds,\n",
    "    runscript_path=template_run,\n",
    "    runname=\"my_new_conus1_run\",\n",
    "    forcing_dir=\"/path/to/your/write/directory\"\n",
    ")\n",
    "\n",
    "#Print out the keys of the new run to confirm the changes\n",
    "run = Run.from_definition(runscript_path)\n",
    "print('-' * 100)\n",
    "print(\"New runname:\", run.get_name())\n",
    "print(\"New grid nx, ny:\", run.ComputationalGrid.NX, run.ComputationalGrid.NY)\n",
    "print(\"Forcing directory:\", run.Solver.CLM.MetFilePath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "757e171d-5538-41d8-be51-32f79293d536",
   "metadata": {},
   "source": [
    "### 4.2 Modify file paths for inputs in the runscript\n",
    "Next we can use the subsettools `change_filename_values` function  (API reference [here](https://hydroframesubsettools.readthedocs.io/en/edit-docs/autoapi/subsettools/subsettools/index.html#subsettools.subsettools.change_filename_values)) to modify the filenames for the input files of our runscript. \n",
    "\n",
    "The filenames which can be updated from this function are: \n",
    "- Slope x (`slopex`)\n",
    "- Slopey y (`slopey`)\n",
    "- Soild File (`solidfile`)\n",
    "- Initial Pressure(`init_press`)\n",
    "- Subsurface Indicator (`indicator`)\n",
    "- Depth to bedrock (`depth_to_bedrock`)\n",
    "- Mannings Roughness (`mannings`)\n",
    "- Evapotranspiration top boundary forcing (`evap_trans`)\n",
    "\n",
    "**NOTE:** Depending on your model configuration you may not have all of these input files and you may also have additional input files. This function just provides a way to reset some of the most common input files from the default if you choose. You can always set keys manually as noted above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0e9c8b13-533e-4bcb-a78a-7534d2e91219",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X Slopes filename changed to slope_x.pfb\n",
      "Y Slopes filename changed to slopy_y.pfb\n",
      "Initial pressure filename changed to init_press.pfb\n",
      "Mannings filename changed to mannings.pfb\n",
      "Updated runscript written to /home/ga6/subsettools_example\n"
     ]
    }
   ],
   "source": [
    "# change the file paths for the initial pressure, mannings and slope_x, slope_y data in the runscript:\n",
    "runscript_path = st.change_filename_values(    \n",
    "    runscript_path=runscript_path,\n",
    "    init_press='init_press.pfb', \n",
    "    mannings='mannings.pfb',\n",
    "    slopex='slope_x.pfb',\n",
    "    slopey='slopy_y.pfb',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc8d9dd-4b3c-42b7-9e8b-c7f6e45bec1b",
   "metadata": {},
   "source": [
    "### 5. Change the processor topology\n",
    "\n",
    "ParFlow is designed to easily scale across multiple processors. To change the number of processors your model is running on you need to do two things: \n",
    "\n",
    "1. **Define your processor topology**: We define the number of processors that the domain will be divided across and we also set the spatial configuration by specifying the number of processors in the `P`, `Q`, `R` directions which correspond to the x,y and z axes respectively. For example a `P`=4, `Q`=2, `R`=1 topology would divided the domain across 8 processors splitting the x axes by 4 and the y axes by 2 but not splitting in the z direction *(NOTE: it its generally best practice not to split in the z direction)*\n",
    "   \n",
    "2. **Distribute input files to mach your processor topology**\n",
    "\n",
    "Here we will use the subsettools `dist_run` function (API reference [here](https://hydroframesubsettools.readthedocs.io/en/edit-docs/autoapi/subsettools/subsettools/index.html#subsettools.subsettools.dist_run)) to modify the processor topology keys and distribute our inputs to our chosen processor topology in one step.  (*Here too you could also accomplish this task by setting keys and distributing files in separate manual calls*). The `dist_run` function will modify the runscript with the values of `P` and `Q` provided. \n",
    "\n",
    "When you later launch the ParFlow simulation, you should make sure to request `P * Q` processors from your computing cluster. The `dist_run` function returns a path to the new runscript that will be created.\n",
    "\n",
    "By default this function will distribute all `.pfb` files in `working_dir`. Because forcing files are so numerous it can take a long time to distribute them so this option can be turned on an off with the `dist_clim_forcing` flag *(Note that if you set the flag to `True`, you should have edited your runscript to include a valid directory to your forcing data - like we did above with the `edit_runscript_for_subset` function).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7299fef8-df9a-448a-9b42-94b4a7d8f2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# distribute input files across 2 grids in the x direction and 2 grids in the y direction\n",
    "runscript_path = st.dist_run(\n",
    "    P=2,\n",
    "    Q=2,\n",
    "    runscript_path=runscript_path,\n",
    "    working_dir='/path/to/the/files/to/be/distributed',\n",
    "    dist_clim_forcing=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a2945b-1079-4e5d-aa88-60660c60a02f",
   "metadata": {},
   "source": [
    "### 7. Change other keys in the runscript\n",
    "\n",
    "The subset tools functions provide functionality for the most common tasks associated with modifying a template run script for a smaller domain. However, the user has full access to every key in the ParFlow yaml file and can adjust any key they would like. \n",
    "\n",
    "To do this we follow these steps:\n",
    "1.  Read in a yaml file and create a `run` object for that runscript using the `from_definition` function (note this could be the template run script or one you have already modified for your subdomain it doesn't matter). \n",
    "2.  Change any keys in the file manually\n",
    "3.  Write the modified `run` object back into the runscript file format using the `write` method of the ParFlow `Run` class.  (The `Run.write()` function takes two arguments, the directory to write the runscript file to and the format (`pfidb` or `yaml`). It returns the path to the created runscript file.)\n",
    "\n",
    "If you want to change many subsurface settings all at once using a table, you can follow this [tutorial](https://parflow.readthedocs.io/en/latest/python/tutorials/sub_tables.html) from the ParFlow documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "03516eff-3da2-4d84-8a71-75a91d9f437a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: Hydraulic conductivity for the indicator group 'b1' is 0.005 m/hour\n",
      "After: Hydraulic conductivity for the indicator group 'b1' is 0.003 m/hour\n"
     ]
    }
   ],
   "source": [
    "run = Run.from_definition(template_run)\n",
    "\n",
    "# for example, we can lower the hydraulic conductivity of one of the bedrock layers:\n",
    "print(\"Before: Hydraulic conductivity for the indicator group \\'b1\\' is\", run.Geom.b1.Perm.Value, \"m/hour\")\n",
    "run.Geom.b1.Perm.Value = 0.003\n",
    "print(\"After: Hydraulic conductivity for the indicator group \\'b1\\' is\", run.Geom.b1.Perm.Value, \"m/hour\")\n",
    "\n",
    "# write the object back into a model runscript:\n",
    "runscript_path, _ = run.write(working_directory='/path/to/your/write/directory', file_format='yaml')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e6e668-e8da-4429-920e-5da02f885696",
   "metadata": {},
   "source": [
    "### 8. Run a ParFlow script\n",
    "\n",
    "Once we have our runscript, we can go ahead a launch a ParFlow simulation!  Note that we assume here that you already have ParFlow installed where you are running. Please refer to the [HydroFrame](https://hydroframe.parflow.org) for help getting started with ParFlow. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaecfa7c-d393-4067-9ecd-ab088ac78bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a run object\n",
    "run = Run.from_definition('/path/to/your/customized/runscript/file')\n",
    "# launch the run\n",
    "run.run(working_dir='/path/to/your/working/directory')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
